数据类型
- string（字符串）
- hash（哈希）
- list（列表）
- set（集合）
- zset(sorted set：有序集合)。
数据结构 
Sds(simple dynamic string)简单动态字符串
- 源代码
```
{
struct sdshdr {

    // 记录 buf 数组中已使用字节的数量
    // 等于 SDS 所保存字符串的长度
    int len;

    // 记录 buf 数组中未使用字节的数量
    int free;

    // 字节数组，用于保存字符串
    char buf[];

};
```

}
- 常数复杂度获取字符串长度
    为了获取一个 C 字符串的长度， 程序必须遍历整个字符串， 对遇到的每个字符进行计数， 直到遇到代表字符串结尾的空字符为止， 这个操作的复杂度为 O(N) 。
SDS 在len属性中记录了 SDS 本身的长度， 所以获取一个 SDS 长度的复杂度仅为O(1)。
设置和更新 SDS 长度的工作是由 SDS 的 API 在执行时自动完成的， 使用 SDS 无需进行任何手动修改长度的工作。
- 杜绝缓冲区溢出
    除了获取字符串长度的复杂度高之外， C 字符串不记录自身长度带来的另一个问题是容易造成缓冲区溢出（buffer overflow）。
当 SDS API 需要对 SDS 进行修改时， API 会先检查 SDS 的空间是否满足修改所需的要求， 如果不满足的话， API 会自动将 SDS 的空间扩展至执行修改所需的大小， 然后才执行实际的修改操作。
- 减少修改字符串时带来的内存重分配次数
每次增长或者缩短一个 C 字符串， 程序都总要对保存这个 C 字符串的数组进行一次内存重分配操作。因为内存重分配涉及复杂的算法， 并且可能需要执行系统调用， 所以它通常是一个比较耗时的操作。
为了避免 C 字符串的这种缺陷， SDS 通过未使用空间解除了字符串长度和底层数组长度之间的关联。通过未使用空间， SDS 实现了空间预分配和惰性空间释放两种优化策略。
- 空间预分配
空间预分配用于优化 SDS 的字符串增长操作： 当 SDS 的 API 对一个 SDS 进行修改， 并且需要对 SDS 进行空间扩展的时候， 程序不仅会为 SDS 分配修改所必须要的空间， 还会为 SDS 分配额外的未使用空间。
其中， 额外分配的未使用空间数量由以下公式决定：
如果对 SDS 进行修改之后， SDS 的长度将小于 1MB ， 那么程序分配和 len 属性同样大小的未使用空间。
如果对 SDS 进行修改之后， SDS 的长度将大于等于 1MB ， 那么程序会分配 1MB 的未使用空间。
在扩展 SDS 空间之前， SDS API 会先检查未使用空间是否足够， 如果足够的话， API 就会直接使用未使用空间， 而无须执行内存重分配。
通过空间预分配策略， Redis 可以减少连续执行字符串增长操作所需的内存重分配次数。
- 惰性空间释放
惰性空间释放用于优化 SDS 的字符串缩短操作： 当 SDS 的 API 需要缩短 SDS 保存的字符串时， 程序并不立即使用内存重分配来回收缩短后多出来的字节， 而是使用 free 属性将这些字节的数量记录起来， 并等待将来使用。你再次操作还是没用到多余空间的时候，Redis也还是会收回对于的空间
通过惰性空间释放策略， SDS 避免了缩短字符串时所需的内存重分配操作， 并为将来可能有的增长操作提供了优化。
与此同时， SDS 也提供了相应的 API ， 让我们可以在有需要时， 真正地释放 SDS 里面的未使用空间， 所以不用担心惰性空间释放策略会造成内存浪费。
链表
- 链表的定义
Redis 实现的链表是一个双向链表
节点:
{
typedef struct listNode {
    struct listNode *prev;  //前置节点
    struct listNode *next;  //后置节点
    void *value;            //节点的值
} listNode;

}
链表:
{
typedef struct list {
    listNode *head;             //表头节点
    listNode *tail;             //表尾节点
    void *(*dup)(void *ptr);    //节点复制函数
    void (*free)(void *ptr);    //节点释放函数
    int (*match)(void *ptr, void *key); //节点值比对函数
    unsigned long len;          //链表包含的节点数量
} list;

}
- 链表特性
双端：链表节点带有 prev 和 next 指针，获取某个节点的前置节点和后置节点的复杂度都是 O(1)。
无环：表头节点的 prev 指针和表尾节点的 next 指针都是指向 NULL，对链表的访问以 NULL 为终点。
通过 list 结构的 head 指针和 tail 指针，获取表头节点和表尾节点的复杂度为 O(1)。
带有链表长度计数器，获取链表长度的复杂度为 O(1)。
多态：链表节点使用 void * 指针来保存各种不同类型的值。
字典
定义
- 字典，又称为符号表（symbol table）、关联数组（associative array）或映射（map），是一种用于保存键值对（key-value pair）的抽象数据结构
实现
- Redis的字典使用哈希表作为底层实现，一个哈希表里面可以有多个哈希表节点，而每个哈希表节点就保存了字典中的一个键值对。
哈希表
typedef struct ditch {

    // 哈希表数组

    dictEntry **table;

    // 哈希表大小

    unsigned long size;

    // 哈希表大小掩码，用于计算索引值

    // 总是等于size-1

    unsigned long sizemask;

    // 该哈希表已有节点的数量

    unsigned long used;

} dictht;

- table属性是一个数组，数组中的每个元素都是一个指向dict.h/dictEntry结构的指针，每个dictEntry结构保存着一个键值对。
- size属性记录了哈希表的大小，也即是table数组的大小。
- used属性则记录了哈希表目前已有节点（键值对）的数量。
- sizemask属性的值总是等于size-1，这个属性和哈希值一起决定一个键应该被放到table数组的哪个索引上面。
哈希表节点
typedef struct dictEntry { 
    // 键 
    void *key; 
    // 值 
    union{ 
        void *val; 
        uint64_tu64; 
        int64_ts64; 
    } v; 
    // 指向下个哈希表节点，形成链表 
    struct dictEntry *next; 
} dictEntry;

- 其中键值对的值可以是一个指针，或者是一个uint64_t整数，又或者是一个int64_t整数。
- next属性是指向另一个哈希表节点的指针，这个指针可以将多个哈希值相同的键值对连接在一次，以此来解决键冲突（collision）的问题。
字典
typedef struct dict { 
    // 类型特定函数 
    dictType *type; 
    // 私有数据 
    void *privdata; 
    // 哈希表 
    dictht ht[2]; 
    // rehash索引 
    // 当rehash不在进行时，值为-1 
    int rehashidx; /* rehashing not in progress if rehashidx == -1 */ 
} dict;

跳跃表
- 好像没啥好说的.
HyperLogLog
概念
- 是用来做基数统计的算法，HyperLogLog 的优点是，在输入元素的数量或者体积非常大时，计算基数所需的空间总是固定的、并且是很小的
命令
PFADD
将任意数量的元素添加到指定的 HyperLogLog 里面。时间复杂度： 每添加一个元素的复杂度为 O(1) 。如果 HyperLogLog 估计的近似基数（approximated cardinality）在命令执行之后出现了变化， 那么命令返回 1 ， 否则返回 0 。 如果命令执行时给定的键不存在， 那么程序将先创建一个空的 HyperLogLog 结构， 然后再执行命令。
# 命令格式：PFADD key element [element …]
# 如果给定的键不存在，那么命令会创建一个空的 HyperLogLog，并向客户端返回 1
127.0.0.1:6379> PFADD ip_20190301 "192.168.0.1" "192.168.0.2" "192.168.0.3"
(integer) 1
# 元素估计数量没有变化，返回 0（因为 192.168.0.1 已经存在）
127.0.0.1:6379> PFADD ip_20190301 "192.168.0.1"
(integer) 0
# 添加一个不存在的元素，返回 1。注意，此时 HyperLogLog 内部存储会被更新，因为要记录新元素
127.0.0.1:6379> PFADD ip_20190301 "192.168.0.4"
(integer) 1

PFCOUNT
当 PFCOUNT key [key …] 命令作用于单个键时，返回储存在给定键的 HyperLogLog 的近似基数，如果键不存在，那么返回 0，复杂度为 O(1)，并且具有非常低的平均常数时间；
当 PFCOUNT key [key …] 命令作用于多个键时，返回所有给定 HyperLogLog 的并集的近似基数，这个近似基数是通过将所有给定 HyperLogLog 合并至一个临时 HyperLogLog 来计算得出的，复杂度为 O(N)，常数时间也比处理单个 HyperLogLog 时要大得多。
# 返回 ip_20190301 包含的唯一元素的近似数量
127.0.0.1:6379> PFCOUNT ip_20190301
(integer) 4
127.0.0.1:6379> PFADD ip_20190301 "192.168.0.5"
(integer) 1
127.0.0.1:6379> PFCOUNT ip_20190301
(integer) 5
127.0.0.1:6379> PFADD ip_20190302 "192.168.0.1" "192.168.0.6" "192.168.0.7"
(integer) 1
# 返回 ip_20190301 和 ip_20190302 包含的唯一元素的近似数量
127.0.0.1:6379> PFCOUNT ip_20190301 ip_20190302
(integer) 7

PFMERGE
将多个 HyperLogLog 合并（merge）为一个 HyperLogLog，合并后的 HyperLogLog 的基数接近于所有输入 HyperLogLog 的可见集合（observed set）的并集。时间复杂度是 O(N)，其中 N 为被合并的 HyperLogLog 数量，不过这个命令的常数复杂度比较高。
命令格式：PFMERGE destkey sourcekey [sourcekey …]，合并得出的 HyperLogLog 会被储存在 destkey 键里面，如果该键并不存在，那么命令在执行之前，会先为该键创建一个空的 HyperLogLog。
# ip_2019030102 是 ip_20190301 与 ip_20190302 并集
127.0.0.1:6379> PFMERGE ip_2019030102 ip_20190301 ip_20190302
OK
127.0.0.1:6379> PFCOUNT ip_2019030102
(integer) 7

SpringBoot 中使用 Redis HyperLogLog
SpringBoot 使用 Redis HyperLogLog
Geo
概念
- Redis 的 Geo 是在 3.2 版本才有的 使用 geohash 保存地理位置的坐标 * 使用有序集合（zset）保存地理位置的集合
命令
- GEOADD：增加某个地理位置的坐标
- GEOPOS：获取某个地理位置的坐标
- GEODIST：获取两个地理位置的距离
- GEORADIUS：根据给定地理位置坐标获取指定范围内的地理位置集合
- GEORADIUSBYMEMBER：根据给定地理位置获取指定范围内的地理位置集合
- GEOHASH：获取某个地理位置的 geohash 值
SpringBoot 使用 Redis Geo
SpringBoot 使用 Redis Geo
Pub/Sub(知道)
- Redis通过publish和subscribe命令实现订阅和发布的功能。
布隆过滤器
概念
- 一种数据结构，是由一串很长的二进制向量组成，可以将其看成一个二进制数组。既然是二进制，那么里面存放的不是0，就是1，但是初始默认值都是0。

优缺点
优点：优点很明显，二进制组成的数组，占用内存极少，并且插入和查询速度都足够快。
缺点：随着数据的增加，误判率会增加；还有无法判断数据一定存在；另外还有一个重要缺点，无法删除数据。
Redis实现布隆过滤器
Redis实现布隆过滤器
guava 工具
- guava 工具包相信大家都用过，谷歌公司提供的，里面也提供了布隆过滤器的实现。
package com.ys.rediscluster.bloomfilter;

import com.google.common.base.Charsets;
import com.google.common.hash.BloomFilter;
import com.google.common.hash.Funnel;
import com.google.common.hash.Funnels;

public class GuavaBloomFilter {
    public static void main(String[] args) {
        BloomFilter<String> bloomFilter = BloomFilter.create(Funnels.stringFunnel(Charsets.UTF_8),100000,0.01);

        bloomFilter.put("10086");

        System.out.println(bloomFilter.mightContain("123456"));
        System.out.println(bloomFilter.mightContain("10086"));
    }
}

持久化
RDB
- RDB 持久化机制是对 Redis 中的数据执行周期性的持久化。
原理
fork和cow。fork是指redis通过创建子进程来进行RDB操作，cow指的是copy on write，子进程创建后，父子进程共享数据段，父进程继续提供读写服务，写脏的页面数据会逐渐和子进程分离开来
优点
- 他会生成多个数据文件，每个数据文件分别都代表了某一时刻Redis里面的数据，这种方式，有没有觉得很适合做冷备，完整的数据运维设置定时任务，定时同步到远端的服务器，比如阿里的云服务，这样一旦线上挂了，你想恢复多少分钟之前的数据，就去远端拷贝一份之前的数据就好了。
- RDB对Redis的性能影响非常小，是因为在同步数据的时候他只是fork了一个子进程去做持久化的，而且他在数据恢复的时候速度比AOF来的快。
缺点
- RDB都是快照文件，都是默认五分钟甚至更久的时间才会生成一次，这意味着你这次同步到下次同步这中间五分钟的数据都很可能全部丢失掉。AOF则最多丢一秒的数据，数据完整性上高下立判。
- RDB在生成数据快照的时候，如果文件很大，客户端可能会暂停几毫秒甚至几秒，你公司在做秒杀的时候他刚好在这个时候fork了一个子进程去生成一个大快照，哦豁，出大问题。
AOF
- AOF 机制对每条写入命令作为日志，以 append-only 的模式写入一个日志文件中，因为这个模式是只追加的方式，所以没有任何磁盘寻址的开销，所以很快
优点
- AOF是一秒一次去通过一个后台的线程fsync操作，那最多丢这一秒的数据。
- AOF在对日志文件进行操作的时候是以append-only的方式去写的，他只是追加的方式写数据，自然就少了很多磁盘寻址的开销了，写入性能惊人，文件也不容易破损。
缺点
- 一样的数据，AOF文件比RDB还要大。
- AOF开启后，Redis支持写的QPS会比RDB支持写的要低，他不是每秒都要去异步刷新一次日志嘛fsync，当然即使这样性能还是很高
Tip
- 两种机制全部开启的时候，Redis在重启的时候会默认使用AOF去重新构建数据，因为AOF的数据是比RDB更完整的
